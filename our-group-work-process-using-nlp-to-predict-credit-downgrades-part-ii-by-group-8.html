<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/theme/css/custom.css" media="screen">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="FINA4350 Students 2023" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="Group8, Progress Report, " />

<meta property="og:title" content="Our Group Work Process: Using NLP to Predict Credit Downgrades, Part II (by &#34;Group 8&#34;) "/>
<meta property="og:url" content="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/our-group-work-process-using-nlp-to-predict-credit-downgrades-part-ii-by-group-8.html" />
<meta property="og:description" content="Our Group Work Process: Using NLP to Predict Credit Downgrades After our midterm progress report, we have made significant strides in completing the scraping of reports from credit rating agencies. We are also in the process of preprocessing and cleaning the data so that it can be tokenized and analyzed …" />
<meta property="og:site_name" content="FINA4350 Student Blog 2023" />
<meta property="og:article:author" content="FINA4350 Students 2023" />
<meta property="og:article:published_time" content="2023-04-30T21:09:00+08:00" />
<meta name="twitter:title" content="Our Group Work Process: Using NLP to Predict Credit Downgrades, Part II (by &#34;Group 8&#34;) ">
<meta name="twitter:description" content="Our Group Work Process: Using NLP to Predict Credit Downgrades After our midterm progress report, we have made significant strides in completing the scraping of reports from credit rating agencies. We are also in the process of preprocessing and cleaning the data so that it can be tokenized and analyzed …">

        <title>Our Group Work Process: Using NLP to Predict Credit Downgrades, Part II (by &#34;Group 8&#34;)  · FINA4350 Student Blog 2023
</title>
        <link href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="FINA4350 Student Blog 2023 - Full Atom Feed" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/"><span class=site-name>FINA4350 Student Blog 2023</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       https://buehlmaier.github.io/FINA4350-student-blog-2023-01
                                    >Home</a>
                                </li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/categories.html">Categories</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/tags.html">Tags</a></li>
                                <li ><a href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/search.html" onsubmit="return validateForm(this.elements['q'].value);"> <input type="text" class="search-query" placeholder="Search" name="q" id="tipue_search_input"></form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/our-group-work-process-using-nlp-to-predict-credit-downgrades-part-ii-by-group-8.html">
                Our Group Work Process: Using NLP to Predict Credit Downgrades, Part II (by "Group 8")
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <h1>Our Group Work Process: Using NLP to Predict Credit Downgrades</h1>
<p>After our midterm progress report, we have made significant strides in completing the scraping of reports from credit rating agencies. We are also in the process of preprocessing and cleaning the data so that it can be tokenized and analyzed. We will then analyze the data using two approaches 1. Human Approach (we create a score) 2. Machine learning model using unsupervised learning for less human bias (clustering)</p>
<ol>
<li><strong>Webscaping</strong>: The main bottleneck in this stage was adjusting the code to account for each stage of the login page loading, along with pop-ups such as requests for cookies or terms and conditions. From a technical perspective, there was lots of Javascript which meant we had to rely on Selenium to webscrape. It was a little difficult to use Selenium at first, especially when Moody (one of the rating agencies) changed their website format as we finished the first iteration of the code. This meant we had to recode the scraping process.</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="c1">#webscraping (code can be reproduced using file moodyScrape.py)</span><span class="w"></span>
<span class="w">    </span><span class="c1"># allow JS/Ajax to load</span><span class="w"></span>
<span class="w">    </span><span class="n">WebDriverWait</span><span class="p">(</span><span class="n">driver</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">until</span><span class="p">(</span><span class="n">EC</span><span class="o">.</span><span class="n">presence_of_element_located</span><span class="p">((</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;//form/div/div/div/input&#39;</span><span class="p">)))</span><span class="w"></span>

<span class="w">    </span><span class="c1">#remove login pop-up</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">driver</span><span class="o">.</span><span class="n">find_element</span><span class="p">(</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;//form/div/div/div/input&#39;</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="o">.</span><span class="n">click</span><span class="p">()</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="o">.</span><span class="n">send_keys</span><span class="p">(</span><span class="s2">&quot;fina4350.nlp@gmail.com&quot;</span><span class="p">)</span><span class="w"> </span><span class="c1"># temp email </span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">driver</span><span class="o">.</span><span class="n">find_element</span><span class="p">(</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;//form/div/button&#39;</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="o">.</span><span class="n">click</span><span class="p">()</span><span class="w"></span>
<span class="w">    </span><span class="n">WebDriverWait</span><span class="p">(</span><span class="n">driver</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">until</span><span class="p">(</span><span class="n">EC</span><span class="o">.</span><span class="n">presence_of_element_located</span><span class="p">((</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;//form/div/div[2]/div/input&#39;</span><span class="p">)))</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">driver</span><span class="o">.</span><span class="n">find_element</span><span class="p">(</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;//form/div/div[2]/div/input&#39;</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="o">.</span><span class="n">click</span><span class="p">()</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="o">.</span><span class="n">send_keys</span><span class="p">(</span><span class="s2">&quot;fina4350&quot;</span><span class="p">)</span><span class="w"> </span><span class="c1"># temp password</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">driver</span><span class="o">.</span><span class="n">find_element</span><span class="p">(</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;//form/div/button&#39;</span><span class="p">)</span><span class="w"></span>
<span class="w">    </span><span class="n">element</span><span class="o">.</span><span class="n">click</span><span class="p">()</span><span class="w"></span>

<span class="w">    </span><span class="c1"># allow JS/Ajax to load</span><span class="w"></span>
<span class="w">    </span><span class="n">WebDriverWait</span><span class="p">(</span><span class="n">driver</span><span class="p">,</span><span class="w"> </span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">until</span><span class="p">(</span><span class="n">EC</span><span class="o">.</span><span class="n">presence_of_element_located</span><span class="p">((</span><span class="n">By</span><span class="o">.</span><span class="n">XPATH</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;//main/div[2]&#39;</span><span class="p">)))</span><span class="w"></span>
<span class="w">    </span><span class="nb">print</span><span class="p">(</span><span class="n">driver</span><span class="o">.</span><span class="n">title</span><span class="p">)</span><span class="w"></span>
</code></pre></div>

<ol>
<li>
<p><strong>Preprocessing of Data</strong>: In terms of preprocessing of data, we had to limit the scope of text scraping on the website to limit the text corpus. This meant we had to identify specific HTML elements we wanted to scrape, making the short walk-through on HTML covered in class very useful for our project. In terms of preprocessing techniques, we used aphanumeric only, along with lemmitization. We still need to get rid of stop words and manual filtering of irrelvant words. Still some ways to go.</p>
</li>
<li>
<p><strong>Tokenization</strong>: Quite a smooth process, we used NLTK only.</p>
</li>
</ol>
<div class="highlight"><pre><span></span><code>#<span class="nv">Preprocessing</span> <span class="ss">(</span><span class="nv">code</span> <span class="nv">can</span> <span class="nv">be</span> <span class="nv">reproduced</span> <span class="nv">using</span> <span class="nv">file</span> <span class="nv">processtext</span>.<span class="nv">py</span><span class="ss">)</span>

<span class="nv">def</span> <span class="nv">processtext</span><span class="ss">(</span><span class="nv">text</span><span class="ss">)</span>:

    # <span class="nv">tokenization</span> <span class="nv">and</span> <span class="nv">pre</span><span class="o">-</span><span class="nv">processing</span>
    <span class="nv">wnl</span> <span class="o">=</span> <span class="nv">WordNetLemmatizer</span><span class="ss">()</span>
    <span class="nv">arr</span> <span class="o">=</span> <span class="nv">list</span><span class="ss">(</span>[<span class="nv">w</span> <span class="k">for</span> <span class="nv">w</span> <span class="nv">in</span> <span class="nv">word_tokenize</span><span class="ss">(</span><span class="nv">text</span>.<span class="nv">lower</span><span class="ss">())</span> <span class="k">if</span> <span class="nv">w</span>.<span class="nv">isalpha</span><span class="ss">()</span>]<span class="ss">)</span>
    <span class="nv">stemmed_arr</span> <span class="o">=</span> [<span class="nv">wnl</span>.<span class="nv">lemmatize</span><span class="ss">(</span><span class="nv">word</span><span class="ss">)</span> <span class="k">for</span> <span class="nv">word</span> <span class="nv">in</span> <span class="nv">arr</span> <span class="k">if</span> <span class="nv">not</span> <span class="nv">word</span> <span class="nv">in</span> <span class="nv">set</span><span class="ss">(</span><span class="nv">stopwords</span>.<span class="nv">words</span><span class="ss">(</span><span class="s1">&#39;</span><span class="s">english</span><span class="s1">&#39;</span><span class="ss">))</span>]
    <span class="nv">print</span><span class="ss">(</span><span class="nv">stemmed_arr</span><span class="ss">)</span>

    <span class="k">return</span> <span class="nv">stemmed_arr</span>
</code></pre></div>

<ol>
<li>
<p><strong>Analysis</strong>: At first, we were a little confused on how we can conduct the quantitative analysis based on the Bag of Words method. During the lectures, we learned that we could apply the concept of sentiment analysis to generate statistical probabilities, which we can then combine with frequency to create a score (a score from -1 to 1). We can also combine this with frequency to create a score. However, there is a risk of errors since the context of words may be incorrectly interpreted. We encountered fewer issues with the machine learning model.</p>
</li>
<li>
<p><strong>Implementation</strong>: We have several initial ideas on how we can implement our analysis on a larger dataset. One idea is that we could use the model from downgrade reports to look at the sentiment on earnings transcripts, but in theory it should work for any textual data that is related to the company. It is important we have a way to adjust to each type of text as the code in webscraping is quite specific to the type of text.</p>
</li>
<li>
<p><strong>Forseeable Limitations</strong>: The code will likely run slow. The entire project also relies on the BoW from Moodys only, as we struggled to scrape from S&amp;P and Fitch. The analysis can also only be applied to the China Real Estate market; we are unsure whether it would work for other industries, or even the RE market in other regions. The amount of manual coding work needed to tweak the scraping parameters make our work very unscalable. Our scraping process is also prone to errors, and even with a sample size of only ~140 texts, our dataset is much smaller than typical studies that analyze thousands of texts."</p>
</li>
</ol>
<p>We are excited to wrap up the project and submit our final report.</p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2023-04-30T21:09:00+08:00">Sun 30 April 2023</time>
            <h4>Category</h4>
            <a class="category-link" href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/categories.html#progress-report-ref">Progress Report</a>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/tags.html#group8-ref">Group8
                    <span class="superscript">2</span>
</a></li>
            </ul>
<h4>Contact</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/buehlmaier/FINA4350-student-blog-2023-01" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
        Powered by: <a href="http://getpelican.com/" title="Pelican Home Page" target="_blank" rel="nofollow noopener noreferrer">Pelican</a>
        Theme: <a href="https://elegant.oncrashreboot.com/" title="Theme Elegant Home Page" target="_blank" rel="nofollow noopener noreferrer">Elegant</a>
    </div>
</footer>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="https://buehlmaier.github.io/FINA4350-student-blog-2023-01/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>